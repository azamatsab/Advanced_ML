{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import math\n",
    "import random\n",
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(8)\n",
    "np.random.seed(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "RUSSIAN_ABC = ' абвгдежзийклмнопрстуфхцчшщъыьэюя'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "RU_PATH = 'corpora/WarAndPeace.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gram_count(lst, n):\n",
    "    \"\"\"Расчет n-gram\"\"\"\n",
    "    return [''.join(lst[i:i + n]) for i in range(len(lst) - n)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cipher_dict(cipher, alphabet_list):\n",
    "    \"\"\"Маппинг букв\"\"\"\n",
    "    cipher_dict = {}\n",
    "    for i in range(len(cipher)):\n",
    "        if i < len(alphabet_list):\n",
    "            cipher_dict[alphabet_list[i].lower()] = cipher[i]\n",
    "    return cipher_dict\n",
    "\n",
    "def apply_cipher_on_text(text, cipher, alphabet_list):\n",
    "    \"\"\"Расшифровать текст используя шифр\"\"\"\n",
    "    cipher_dict = create_cipher_dict(cipher, alphabet_list)\n",
    "    text = list(text)\n",
    "    newtext = \"\"\n",
    "    for elem in text:\n",
    "        newtext += cipher_dict[elem.lower()]\n",
    "    return newtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_grams_in_text(text, n=2):\n",
    "    \"\"\"Подсчитать количество n-gram в тексте\"\"\"\n",
    "    text = text.lower().strip()\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    n_grams = gram_count(list(text), n)\n",
    "    scoring_params = Counter(n_grams)\n",
    "    return scoring_params\n",
    "\n",
    "def count_grams_in_longtext(longtext_path, n=2):\n",
    "    \"\"\"Подсчитать количество n-gram в корпусе\"\"\"\n",
    "    scoring_params = {}\n",
    "    scoring_params = Counter(list(''))\n",
    "    with open(longtext_path) as fp:\n",
    "        for line in fp:\n",
    "            scoring_params += count_grams_in_text(line, n=n)\n",
    "    return scoring_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1\n",
    "Реализуйте базовый частотный метод по Шерлоку Холмсу:\n",
    "- подсчитайте частоты букв по корпусам (пунктуацию и капитализацию можно просто опустить, а вот пробелы лучше оставить);\n",
    "- возьмите какие-нибудь тестовые тексты (нужно взять по меньшей мере 2-3 предложения, иначе вряд ли сработает), зашифруйте их посредством случайной перестановки символов;\n",
    "- расшифруйте их таким частотным методом.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Напишем исходный текст:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_text = \"\"\"я сделал все дополнительные пункты во втором домашнем заданий, \n",
    "но не получил ни одного балла за них, \n",
    "если у вас есть время, хотелось бы узнать в чем была ошибка, ведь это часть учебного процесса. \n",
    "Пользуясь случаем, хочу выразить Вам огромную благодарность за этот курс. \n",
    "Это один из лучших курсов, которые я проходил и наверное самый интересный. \n",
    "Никогда не думал, что буду читать и понимать Бишопа) \n",
    "Надеюсь найти время еще раз прослушать Ваши лекций и проработать все темы, \n",
    "так как понимаю, что нужно приложить еще больше усилий, чтобы освоить материалы. \n",
    "Еще раз спасибо! \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'я сделал все дополнительные пункты во втором домашнем заданий но не получил ни одного балла за них если у вас есть время хотелось бы узнать в чем была ошибка ведь это часть учебного процесса Пользуясь случаем хочу выразить Вам огромную благодарность за этот курс Это один из лучших курсов которые я проходил и наверное самый интересный Никогда не думал что буду читать и понимать Бишопа Надеюсь найти время еще раз прослушать Ваши лекций и проработать все темы так как понимаю что нужно приложить еще больше усилий чтобы освоить материалы Еще раз спасибо '"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_text = source_text.replace('\\n','')\n",
    "source_text = re.sub(r'[^\\w\\s]', '', source_text)\n",
    "source_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Применим случайный шифр к тексту и получим зашифрованный текст"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Зашифрованный текст:\n",
      "еавыиржраявиаыгцгрмьширом иацюмкш аягаяшгэгхаыгхжтмихащжыжмьсамгамиацгрюзьрамьагымгдгалжрржащжамьпаиврьаюаяжваившоаяэихеапгширгвоал ающмжшоаяазихал ржагтьлкжаяиыоаушгазжвшоаюзилмгдгацэгниввжацгрощюевоаврюзжихапгзюая эжщьшоаяжхагдэгхмюйалрждгыжэмгвшоащжаушгшакюэваушгагыьмаьщарюзтьпакюэвгяакгшгэ иаеацэгпгыьраьамжяиэмгиавжх саьмшиэивм самькгдыжамиаыюхжразшгалюыюазьшжшоаьацгмьхжшоальтгцжамжыийвоамжсшьаяэихеаиъиаэжщацэгврютжшоаяжтьарикньсаьацэгэжлгшжшоаявиаших ашжкакжкацгмьхжйазшгамюбмгацэьргбьшоаиъиалгротиаювьрьсазшгл агвягьшоахжшиэьжр аиъиаэжщавцжвьлга\n",
      "Шифр: ['ы' ' ' 'ж' 'с' 'о' 'г' 'я' 'а' 'ч' 'е' 'ю' 'к' 'б' 'н' 'ц' 'ь' 'х' 'л'\n",
      " 'й' 'ш' 'э' 'ф' 'м' 'п' 'ъ' 'т' 'з' 'щ' 'д' 'и' 'р' 'у' 'в'] 33\n"
     ]
    }
   ],
   "source": [
    "cipher = np.random.permutation(list(RUSSIAN_ABC))\n",
    "\n",
    "encr_text = apply_cipher_on_text(source_text.lower(), RUSSIAN_ABC, cipher)\n",
    "\n",
    "print(\"Зашифрованный текст:\")\n",
    "print(encr_text)\n",
    "print(\"Шифр:\", cipher, len(cipher))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1\n",
    "alphabet_list = list(RUSSIAN_ABC)\n",
    "\n",
    "target_counts = count_grams_in_text(encr_text, n)\n",
    "source_counts = count_grams_in_longtext(RU_PATH, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_abc = target_counts.most_common(len(target_counts))\n",
    "source_abc = source_counts.most_common(len(target_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_cipher = [\" \" for _ in range(len(alphabet_list))]\n",
    "for tar, src in zip(target_abc, source_abc):\n",
    "    ind = alphabet_list.index(tar[0])\n",
    "    pred_cipher[ind] = src[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'й суелал дсе уополтинелртге пктынг до дновом уомабтем зауатич то те полкьил ти оутожо яалла за тиш если к дас еснр двемй шонелоср яг кзтанр д ьем ягла обияыа деур хно ьаснр кьеятожо пвоцесса полрзкйср слкьаем шоьк дгвазинр дам ожвомткe ялажоуавтоснр за хнон ыквс хно оуит из лкьбиш ыквсод ыоновге й пвошоуил и тадевтое самгч итневестгч тиыожуа те укмал ьно якук ьинанр и потиманр яибопа тауеeср тачни двемй еюе ваз пвослкбанр даби леыцич и пвоваяонанр дсе немг наы ыаы потимаe ьно ткnто пвилоnинр еюе яолрбе ксилич ьнояг осдоинр маневиалг еюе ваз спасияо '"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apply_cipher_on_text(encr_text, pred_cipher, alphabet_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Все очень плохо (("
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2\n",
    "Вряд ли в результате получилась такая уж хорошая расшифровка, разве что если вы брали в качестве тестовых данных целые рассказы. Но и Шерлок Холмс был не так уж прост: после буквы E, которая действительно выделяется частотой, дальше он анализировал уже конкретные слова и пытался угадать, какими они могли бы быть. Я не знаю, как запрограммировать такой интуитивный анализ, так что давайте просто сделаем следующий логический шаг:\n",
    " - подсчитайте частоты биграмм (т.е. пар последовательных букв) по корпусам;\n",
    " - проведите тестирование аналогично п.1, но при помощи биграмм."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### К сожалению этот пункт пуст"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3\n",
    "Но и это ещё не всё: биграммы скорее всего тоже далеко не всегда работают. Основная часть задания — в том, как можно их улучшить:\n",
    "\n",
    "- предложите метод обучения перестановки символов в этом задании, основанный на MCMC-сэмплировании, но по-прежнему работающий на основе статистики биграмм;\n",
    "- реализуйте и протестируйте его, убедитесь, что результаты улучшились."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Предположим, что Марковская цепь для этой задачи имеет просторанство состоянии $X$, состоящих из всех возможных шифр.\n",
    "В таком случае, для расчета стационарного распределения этой цепи используем сэмплирование по Метрополису-Гастингсу\n",
    "\n",
    "$r(b_1, b_2)$ - количество биграмм $b_1b_2$ - в корпусе текста WarAndPeace.txt\n",
    "\n",
    "$f(b_1, b_2)$ - количество биграмм $b_1b_2$ - в расшифрованном ключом $x$ тексте. ($x$ принадлежит $X$)\n",
    " \n",
    "Для расчета правдоподобия используем следующую формулу:\n",
    "\n",
    "$L = \\prod_{i=1}^{N} r(b_1, b_2) ^ {f(b_1, b_2)}$\n",
    "\n",
    "Логарифм правдоподобия:\n",
    "\n",
    "$L = \\sum_{i=1}^{N} f(b_1, b_2) * log(r(b_1, b_2))$\n",
    "\n",
    "В качестве q сэмплирования будем менять случайные две буквы местами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cipher_score(text, cipher, scoring_params, alphabet_list, n):\n",
    "    \"\"\"Расчет логарифма правдоподобия\"\"\"\n",
    "    decrypted_text = apply_cipher_on_text(text, cipher, alphabet_list)\n",
    "    scored_f = count_grams_in_text(decrypted_text, n=n)\n",
    "    cipher_score = 0\n",
    "    for k, v in scored_f.items():\n",
    "        if k in scoring_params:\n",
    "            cipher_score += v * math.log(scoring_params[k])\n",
    "    return cipher_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_cipher(cipher):\n",
    "    \"\"\"Сэмплировать шифр из распределения q\"\"\"\n",
    "    pos1 = random.randint(0, len(list(cipher)) - 1)\n",
    "    pos2 = random.randint(0, len(list(cipher)) - 1)\n",
    "    if pos1 == pos2:\n",
    "        return generate_cipher(cipher)\n",
    "    else:\n",
    "        cipher = list(cipher)\n",
    "        pos1_alpha = cipher[pos1]\n",
    "        pos2_alpha = cipher[pos2]\n",
    "        cipher[pos1] = pos2_alpha\n",
    "        cipher[pos2] = pos1_alpha\n",
    "        return \"\".join(cipher)\n",
    "\n",
    "def random_coin(p):\n",
    "    unif = random.uniform(0, 1)\n",
    "    if unif >= p:\n",
    "        return False\n",
    "    else:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MCMC_decrypt(n_iter, cipher_text, scoring_params, alphabet_list, n=2):\n",
    "    \"\"\"Алгоритм Метрополиса-Гастингса\"\"\"\n",
    "    current_cipher = RUSSIAN_ABC\n",
    "    best_state = ''\n",
    "    score = 0\n",
    "    accepted = 0\n",
    "    ciphers = {}\n",
    "    for i in range(n_iter):\n",
    "        proposed_cipher = generate_cipher(current_cipher)\n",
    "        score_current_cipher = get_cipher_score(cipher_text, current_cipher, scoring_params, alphabet_list, n)\n",
    "        score_proposed_cipher = get_cipher_score(cipher_text, proposed_cipher, scoring_params, alphabet_list, n)\n",
    "        acceptance_probability = min(1, math.exp(score_proposed_cipher - score_current_cipher))\n",
    "\n",
    "        if score_current_cipher > score:\n",
    "            score = score_current_cipher\n",
    "            best_state = current_cipher\n",
    "        if random_coin(acceptance_probability):\n",
    "            accepted += 1\n",
    "            current_cipher = proposed_cipher\n",
    "            if proposed_cipher in ciphers:\n",
    "                ciphers[proposed_cipher] += 1\n",
    "            else:\n",
    "                ciphers[proposed_cipher] = 1\n",
    "        if i % PRINT_STEPS == 0:\n",
    "            print(\"iter\", i, \":\", apply_cipher_on_text(cipher_text, current_cipher, alphabet_list) + \"\\n\")\n",
    "    print(f\"Iterations {n_iter}, accepted {accepted}, rejected {n_iter - accepted}\")\n",
    "    return ciphers, best_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 0 : еавыиржраявиаыгнгрмьширом ианюмкш аягаяшгэгхаыгхжтмихащжыжмьсамгамиангрюзьрамьагымгдгалжрржащжамьпаиврьаюаяжваившоаяэихеапгширгвоал ающмжшоаяазихал ржагтьлкжаяиыоаушгазжвшоаюзилмгдганэгциввжангрощюевоаврюзжихапгзюая эжщьшоаяжхагдэгхмюйалрждгыжэмгвшоащжаушгшакюэваушгагыьмаьщарюзтьпакюэвгяакгшгэ иаеанэгпгыьраьамжяиэмгиавжх саьмшиэивм самькгдыжамиаыюхжразшгалюыюазьшжшоаьангмьхжшоальтгнжамжыийвоамжсшьаяэихеаиъиаэжщанэгврютжшоаяжтьарикцьсаьанэгэжлгшжшоаявиаших ашжкакжкангмьхжйазшгамюбмганэьргбьшоаиъиалгротиаювьрьсазшгл агвягьшоахжшиэьжр аиъиаэжщавнжвьлга\n",
      "\n",
      "iter 15000 : я сделал все дополнительные пункты во втором домашнем заданий но не получил ни одного балла за них если у вас есть время хотелось бы узнать в чем была ошибка ведь это часть учебного процесса пользуясь случаем хочу выразить вам огромную благодарность за этот курс это один из лучших курсов которые я проходил и наверное самый интересный никогда не думал что буду читать и понимать бишопа надеюсь найти время еще раз прослушать ваши лекций и проработать все темы так как понимаю что нужно приложить еще больше усилий чтобы освоить материалы еще раз спасибо \n",
      "\n",
      "iter 30000 : я сделал все дополнительные пункты во втором домашнем заданий но не получил ни одного балла за них если у вас есть время хотелось бы узнать в чем была ошибка ведь это часть учебного процесса пользуясь случаем хочу выразить вам огромную благодарность за этот курс это один из лучших курсов которые я проходил и наверное самый интересный никогда не думал что буду читать и понимать бишопа надеюсь найти время еще раз прослушать ваши лекций и проработать все темы так как понимаю что нужно приложить еще больше усилий чтобы освоить материалы еще раз спасибо \n",
      "\n",
      "iter 45000 : я сделал все дополнительные пункты во втором домашнем заданий но не получил ни одного балла за них если у вас есть время хотелось бы узнать в чем была ошибка ведь это часть учебного прощесса пользуясь случаем хочу выразить вам огромную благодарность за этот курс это один из лучших курсов которые я проходил и наверное самый интересный никогда не думал что буду читать и понимать бишопа надеюсь найти время еце раз прослушать ваши лекщий и проработать все темы так как понимаю что нужно приложить еце больше усилий чтобы освоить материалы еце раз спасибо \n",
      "\n",
      "iter 60000 : я сделал все дополнительные пункты во втором домашнем заданий но не получил ни одного балла за них если у вас есть время хотелось бы узнать в чем была ошибка ведь это часть учебного процесса пользуясь случаем хочу выразить вам огромную благодарность за этот курс это один из лучших курсов которые я проходил и наверное самый интересный никогда не думал что буду читать и понимать бишопа надеюсь найти время еще раз прослушать ваши лекций и проработать все темы так как понимаю что нужно приложить еще больше усилий чтобы освоить материалы еще раз спасибо \n",
      "\n",
      "iter 75000 : я сделал все дополнительные пункты во втором домашнем заданий но не получил ни одного балла за них если у вас есть время хотелось бы узнать в чем была ошибка ведь это часть учебного процесса пользуясь случаем хочу выразить вам огромную благодарность за этот курс это один из лучших курсов которые я проходил и наверное самый интересный никогда не думал что буду читать и понимать бишопа надеюсь найти время еще раз прослушать ваши лекций и проработать все темы так как понимаю что нужно приложить еще больше усилий чтобы освоить материалы еще раз спасибо \n",
      "\n",
      "iter 90000 : я сделал все дополнительные пункты во втором домашнем заданий но не получил ни одного балла за них если у вас есть время хотелось бы узнать в чем была ошибка ведь это часть учебного процесса пользуясь случаем хочу выразить вам огромную благодарность за этот курс это один из лучших курсов которые я проходил и наверное самый интересный никогда не думал что буду читать и понимать бишопа надеюсь найти время еще раз прослушать ваши лекций и проработать все темы так как понимаю что нужно приложить еще больше усилий чтобы освоить материалы еще раз спасибо \n",
      "\n",
      "Iterations 100000, accepted 374, rejected 99626\n"
     ]
    }
   ],
   "source": [
    "n = 2\n",
    "\n",
    "alphabet_list = list(RUSSIAN_ABC)\n",
    "\n",
    "scoring_params = count_grams_in_longtext(RU_PATH, n=n)\n",
    "encryption_key = RUSSIAN_ABC\n",
    "PRINT_STEPS = 15000\n",
    "\n",
    "states, best_state = MCMC_decrypt(100000, encr_text, scoring_params, alphabet_list, n=n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Принято всего лишь 374 состоянии, думаю это из-за не очень хорошего q распределения, но ничего лучше придумать не смог"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Хотя получили всего лишь 374 точек, получим из этого распределния наиболее вероятный шифр и расшифруем текст"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "cipher = Counter(states).most_common(1)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'я сделал все дополнительные пункты во втором домашнем заданий но не получил ни одного балла за них если у вас есть время хотелось бы узнать в чем была ошибка ведь это часть учебного процесса пользуясь случаем хочу выразить вам огромную благодарность за этот курс это один из лучших курсов которые я проходил и наверное самый интересный никогда не думал что буду читать и понимать бишопа надеюсь найти время еще раз прослушать ваши лекций и проработать все темы так как понимаю что нужно приложить еще больше усилий чтобы освоить материалы еще раз спасибо '"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apply_cipher_on_text(encr_text, cipher, alphabet_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Лучше чем первые 2 метода"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Расшифруйте сообщение:\n",
    "←⇠⇒↟↹↷⇊↹↷↟↤↟↨←↹↝⇛⇯↳⇴⇒⇈↝⇊↾↹↟⇒↟↹⇷⇛⇞↨↟↹↝⇛⇯↳⇴⇒⇈↝⇊↾↹↨←⇌⇠↨↹⇙↹⇸↨⇛↙⇛↹⇠⇛⇛↲⇆←↝↟↞↹⇌⇛↨⇛⇯⇊↾↹⇒←↙⇌⇛↹⇷⇯⇛⇞↟↨⇴↨⇈↹⇠⇌⇛⇯←←↹↷⇠←↙⇛↹↷⇊↹↷⇠←↹⇠↤←⇒⇴⇒↟↹⇷⇯⇴↷↟⇒⇈↝⇛↹↟↹⇷⇛⇒⇙⇞↟↨←↹↳⇴⇌⇠↟↳⇴⇒⇈↝⇊↾↹↲⇴⇒⇒↹⇰⇴↹⇷⇛⇠⇒←↤↝←←↹⇞←↨↷←⇯↨⇛←↹⇰⇴↤⇴↝↟←↹⇌⇙⇯⇠⇴↹↘⇛↨↞↹⇌⇛↝←⇞↝⇛↹↞↹↝↟⇞←↙⇛↹↝←↹⇛↲←⇆⇴⇏\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "plain_text = 'დჳჵჂႨშႼႨშჂხჂჲდႨსႹႭჾႣჵისႼჰႨჂჵჂႨႲႹႧჲჂႨსႹႭჾႣჵისႼჰႨჲდႩჳჲႨჇႨႠჲႹქႹႨჳႹႹჱჶდსჂႽႨႩႹჲႹႭႼჰႨჵდქႩႹႨႲႭႹႧჂჲႣჲიႨჳႩႹႭდდႨშჳდქႹႨშႼႨშჳდႨჳხდჵႣჵჂႨႲႭႣშჂჵისႹႨჂႨႲႹჵჇႧჂჲდႨჾႣႩჳჂჾႣჵისႼჰႨჱႣჵჵႨეႣႨႲႹჳჵდხსდდႨႧდჲშდႭჲႹდႨეႣხႣსჂდႨႩჇႭჳႣႨႾႹჲႽႨႩႹსდႧსႹႨႽႨსჂႧდქႹႨსდႨႹჱდჶႣნ'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 0 : мчшквтзвткукнмврждъашорзфвкшквежбнкврждъашорзфвнмгчнвлв нжсжвчжжхщмркивгжнждзфвшмсгжведжбкнановчгждммвтчмсжвтзвтчмвчумшашкведаткшоржвквежшлбкнмвъагчкъашорзфвхашшвцавежчшмурммвбмнтмднжмвцауаркмвглдчавйжнивгжрмбржвивркбмсжврмвжхмщап\n",
      "\n",
      "iter 30000 : осли вы викито недчальный или жерти недчальный томст у этебе сеегшония метедый лобме ждеритать смедоо всобе вы всо сколали ждавильне и желурито чамсичальный галл за жеслокноо ротводтео заканио мудса петя менорне я ниробе но егошаъ\n",
      "\n",
      "iter 60000 : осли вы вимито неркальный или пегти неркальный тодст у чтеже сеезбония детерый ложде прегитать сдероо всоже вы всо смолали правильне и пелугито кадсикальный залл ха песломноо готвортео хаманио дурса шетя деногне я нигоже но езобаъ\n",
      "\n",
      "iter 90000 : осли вы викито нерзальный или пемти нерзальный тодст у этеже сеегчония детерый ложде премитать сдероо всоже вы всо сколали правильне и пелумито задсизальный галл ба песлокноо мотвортео баканио дурса шетя деномне я ниможе но егочаъ\n",
      "\n",
      "iter 120000 : осли вы викито нерзальный или пемти нерзальный тодст у этеже сеегбония детерый ложде премитать сдероо всоже вы всо сколали правильне и пелумито задсизальный галл ча песлокноо мотвортео чаканио дурса цетя деномне я ниможе но егобаъ\n",
      "\n",
      "iter 150000 : осли вы викито нерзальный или пемти нерзальный тодст у этеже сеегхония детерый ложде премитать сдероо всоже вы всо сколали правильне и пелумито задсизальный галл ча песлокноо мотвортео чаканио дурса бетя деномне я ниможе но егохаш\n",
      "\n",
      "iter 180000 : осли вы викито нерзальный или пемти нерзальный тодст у этеже сеегшония детерый ложде премитать сдероо всоже вы всо сколали правильне и пелумито задсизальный галл ча песлокноо мотвортео чаканио дурса бетя деномне я ниможе но егошах\n",
      "\n",
      "iter 210000 : если вы вимите норзальный или подти норзальный текст у этого соочшения который легко продитать скорее всего вы все смелали правильно и полудите заксизальный чалл ба послемнее детвертое бамание курса хотя конедно я нидего не очешац\n",
      "\n",
      "iter 240000 : если вы вимите норжальный или подти норжальный текст у чтого сообщения который легко продитать скорее всего вы все смелали правильно и полудите жаксижальный балл за послемнее детвертое замание курса хотя конедно я нидего не обещаэ\n",
      "\n",
      "iter 270000 : если вы вимите нордальный или почти нордальный текст у этого соошбения который легко прочитать скорее всего вы все смелали правильно и получите даксидальный шалл за послемнее четвертое замание курса хотя конечно я ничего не ошебаж\n",
      "\n",
      "iter 300000 : если вы вимите норжальный или подти норжальный текст у этого сообчения который легко продитать скорее всего вы все смелали правильно и полудите жаксижальный балл за послемнее детвертое замание курса шотя конедно я нидего не обечаф\n",
      "\n",
      "iter 330000 : если вы вимите норжальный или подти норжальный текст у чтого сообшения который легко продитать скорее всего вы все смелали правильно и полудите жаксижальный балл за послемнее детвертое замание курса хотя конедно я нидего не обешаю\n",
      "\n",
      "iter 360000 : если вы вимите норшальный или подти норшальный текст у чтого соожщения который легко продитать скорее всего вы все смелали правильно и полудите шаксишальный жалл за послемнее детвертое замание курса ботя конедно я нидего не ожещаэ\n",
      "\n",
      "iter 390000 : если вы вимите норшальный или подти норшальный текст у этого сообчения который легко продитать скорее всего вы все смелали правильно и полудите шаксишальный балл за послемнее детвертое замание курса хотя конедно я нидего не обечащ\n",
      "\n",
      "iter 420000 : если вы вижите нордальный или помти нордальный текст у этого соочшения который легко промитать скорее всего вы все сжелали правильно и полумите даксидальный чалл за послежнее метвертое зажание курса ботя конемно я нимего не очешаю\n",
      "\n",
      "iter 450000 : если вы вимите норшальный или подти норшальный текст у этого соожбения который легко продитать скорее всего вы все смелали правильно и полудите шаксишальный жалл за послемнее детвертое замание курса хотя конедно я нидего не ожебац\n",
      "\n",
      "iter 480000 : если вы вимите норжальный или подти норжальный текст у этого сообчения который легко продитать скорее всего вы все смелали правильно и полудите жаксижальный балл за послемнее детвертое замание курса хотя конедно я нидего не обечаф\n",
      "\n",
      "iter 510000 : если вы вимите норшальный или почти норшальный текст у этого соождения который легко прочитать скорее всего вы все смелали правильно и получите шаксишальный жалл за послемнее четвертое замание курса ботя конечно я ничего не ожедац\n",
      "\n",
      "iter 540000 : если вы вимите норзальный или подти норзальный текст у чтого соошжения который легко продитать скорее всего вы все смелали правильно и полудите заксизальный шалл ба послемнее детвертое бамание курса хотя конедно я нидего не ошежаэ\n",
      "\n",
      "iter 570000 : если вы вимите норжальный или подти норжальный текст у этого сообщения который легко продитать скорее всего вы все смелали правильно и полудите жаксижальный балл ча послемнее детвертое чамание курса хотя конедно я нидего не обещаю\n",
      "\n",
      "iter 600000 : если вы вимите норжальный или подти норжальный текст у этого соочшения который легко продитать скорее всего вы все смелали правильно и полудите жаксижальный чалл за послемнее детвертое замание курса ботя конедно я нидего не очешащ\n",
      "\n",
      "iter 630000 : если вы вимите норзальный или подти норзальный текст у этого соожчения который легко продитать скорее всего вы все смелали правильно и полудите заксизальный жалл ха послемнее детвертое хамание курса ботя конедно я нидего не ожечащ\n",
      "\n",
      "iter 660000 : если вы вимите норзальный или подти норзальный текст у этого соочшения который легко продитать скорее всего вы все смелали правильно и полудите заксизальный чалл жа послемнее детвертое жамание курса ботя конедно я нидего не очешах\n",
      "\n",
      "iter 690000 : если вы вимите норжальный или подти норжальный текст у этого соочшения который легко продитать скорее всего вы все смелали правильно и полудите жаксижальный чалл за послемнее детвертое замание курса ботя конедно я нидего не очешаъ\n",
      "\n",
      "iter 720000 : если вы вимите норзальный или подти норзальный текст у этого сообщения который легко продитать скорее всего вы все смелали правильно и полудите заксизальный балл ча послемнее детвертое чамание курса хотя конедно я нидего не обещаш\n",
      "\n",
      "iter 750000 : если вы вимите норшальный или подти норшальный текст у этого соожчения который легко продитать скорее всего вы все смелали правильно и полудите шаксишальный жалл за послемнее детвертое замание курса ботя конедно я нидего не ожечаф\n",
      "\n",
      "iter 780000 : если вы вимите норзальный или подти норзальный текст у этого сообчения который легко продитать скорее всего вы все смелали правильно и полудите заксизальный балл жа послемнее детвертое жамание курса хотя конедно я нидего не обечащ\n",
      "\n",
      "iter 810000 : если вы вимите норзальный или почти норзальный тедст у этого соожбения доторый легдо прочитать сдорее всего вы все смелали правильно и получите задсизальный жалл ка послемнее четвертое камание дурса хотя донечно я ничего не ожебаъ\n",
      "\n",
      "iter 840000 : если вы вимите норзальный или подти норзальный текст у этого сообщения который легко продитать скорее всего вы все смелали правильно и полудите заксизальный балл ча послемнее детвертое чамание курса хотя конедно я нидего не обещаъ\n",
      "\n",
      "iter 870000 : если вы вимите нордальный или почти нордальный текст у этого сообщения который легко прочитать скорее всего вы все смелали правильно и получите даксидальный балл за послемнее четвертое замание курса хотя конечно я ничего не обещаю\n",
      "\n",
      "Iterations 900000, accepted 31311, rejected 868689\n"
     ]
    }
   ],
   "source": [
    "n = 2\n",
    "\n",
    "alphabet_list = sorted(list(set(plain_text)))\n",
    "\n",
    "scoring_params = count_grams_in_longtext(RU_PATH, n=n)\n",
    "\n",
    "PRINT_STEPS = 30000\n",
    "states, best_state = MCMC_decrypt(900000, plain_text, scoring_params, alphabet_list, n=n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## в 870000 итерации \"м\" и \"д\" поменяны местами, остальные норм)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### посмотрим на наиболее вероятный шифр"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "cipher = Counter(states).most_common(1)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'если вы вимите норзальный или подти норзальный текст у этого сообщения который легко продитать скорее всего вы все смелали правильно и полудите заксизальный балл ча послемнее детвертое чамание курса хотя конедно я нидего не обещац'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apply_cipher_on_text(plain_text, cipher, alphabet_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### получилось хуже чем некоторые шифры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Бонус: \n",
    "а что если от биграмм перейти к триграммам (тройкам букв) или даже больше? Улучшатся ли результаты? Когда улучшатся, а когда нет? Чтобы ответить на этот вопрос эмпирически, уже может понадобиться погенерировать много тестовых перестановок и последить за метриками, глазами может быть и не видно"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Посмотрим на 3 грамм"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 0 : мчшквтзвткукнмврждъашорзфвкшквежбнкврждъашорзфвнмгчнвлв нжсжвчжжхщмркивгжнждзфвшмсгжведжбкнановчгждммвтчмсжвтзвтчмвчумшашкведаткшоржвквежшлбкнмвъагчкъашорзфвхашшвцавежчшмурммвбмнтмднжмвцауаркмвглдчавйжнивгжрмбржвивркбмсжврмвжхмщап\n",
      "\n",
      "iter 15000 : если вы видите норжальный или почти норжальный текст у этого сообщения который легко прочитать скорее всего вы все сделали правильно и получите жаксижальный балл за последнее четвертое задание курса мотя конечно я ничего не обещаш\n",
      "\n",
      "iter 30000 : если вы видите нормальный или почти нормальный текст у этого сообщения который легко прочитать скорее всего вы все сделали правильно и получите максимальный балл за последнее четвертое задание курса хотя конечно я ничего не обещаю\n",
      "\n",
      "Iterations 40000, accepted 1289, rejected 38711\n"
     ]
    }
   ],
   "source": [
    "n = 3\n",
    "\n",
    "alphabet_list = sorted(list(set(plain_text)))\n",
    "\n",
    "scoring_params = count_grams_in_longtext(RU_PATH, n=n)\n",
    "PRINT_STEPS = 15000\n",
    "\n",
    "states, best_state = MCMC_decrypt(40000, plain_text, scoring_params, alphabet_list, n=n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 граммой получили идеальный результат. Посмотрим на 4-gramm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 0 : мчшквтзвткукцмврждъашорзфвкшквежбцкврждъашорзфвцмгчцвлв цжсжвчжжхщмркивгжцждзфвшмсгжведжбкцацовчгждммвтчмсжвтзвтчмвчумшашкведаткшоржвквежшлбкцмвъагчкъашорзфвхашшвнавежчшмурммвбмцтмдцжмвнауаркмвглдчавйжцивгжрмбржвивркбмсжврмвжхмщап\n",
      "\n",
      "iter 15000 : еоли пр пибине втумалыврь или чтдни втумалыврь несон к шнтжт оттфхевия стнтурь лежст чутдинаны остуее поежт пр пое обелали чуапилывт и чтлкдине масоималыврь фалл за чтолебвее денпеунте забавие скуоа этня стведвт я видежт ве тфехаю\n",
      "\n",
      "iter 30000 : еоли пр пибине втумалыврь или чтдни втумалыврь несон к гнтхт оттжшевия стнтурь лехст чутдинаны остуее поехт пр пое обелали чуапилывт и чтлкдине масоималыврь жалл за чтолебвее денпеунте забавие скуоа этня стведвт я видехт ве тжешай\n",
      "\n",
      "iter 45000 : еоли пр пибине втумалыврь или чтдни втумалыврь несон к гнтют оттжщевия стнтурь леюст чутдинаны остуее поеют пр пое обелали чуапилывт и чтлкдине масоималыврь жалл за чтолебвее денпеунте забавие скуоа этня стведвт я видеют ве тжещай\n",
      "\n",
      "iter 60000 : еоли пр пибине втумалыврь или чтдни втумалыврь несон к цнтют оттжщевия стнтурь леюст чутдинаны остуее поеют пр пое обелали чуапилывт и чтлкдине масоималыврь жалл за чтолебвее денпеунте забавие скуоа этня стведвт я видеют ве тжещах\n",
      "\n",
      "iter 75000 : еоли пр пибине втумалыврь или чтдни втумалыврь несон к цнтют оттжъевия стнтурь леюст чутдинаны остуее поеют пр пое обелали чуапилывт и чтлкдине масоималыврь жалл за чтолебвее денпеунте забавие скуоа этня стведвт я видеют ве тжеъаш\n",
      "\n",
      "iter 90000 : еоли пр пибине втумалыврь или чтдни втумалыврь несон к гнтют оттжцевия стнтурь леюст чутдинаны остуее поеют пр пое обелали чуапилывт и чтлкдине масоималыврь жалл за чтолебвее денпеунте забавие скуоа этня стведвт я видеют ве тжецай\n",
      "\n",
      "Iterations 100000, accepted 4768, rejected 95232\n"
     ]
    }
   ],
   "source": [
    "n = 4\n",
    "\n",
    "alphabet_list = sorted(list(set(plain_text)))\n",
    "\n",
    "scoring_params = count_grams_in_longtext(RU_PATH, n=n)\n",
    "PRINT_STEPS = 15000\n",
    "\n",
    "states, best_state = MCMC_decrypt(100000, plain_text, scoring_params, alphabet_list, n=n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## тут все плохо. Очередь за 5-gramm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 0 : мчшквтзвткукцмврждъашорзювкшквежбцкврждъашорзювцмгчцвлв цжсжвчжжхщмркивгжцждзювшмсгжведжбкцацовчгждммвтчмсжвтзвтчмвчумшашкведаткшоржвквежшлбкцмвъагчкъашорзювхашшвнавежчшмурммвбмцтмдцжмвнауаркмвглдчавйжцивгжрмбржвивркбмсжврмвжхмщап\n",
      "\n",
      "iter 15000 : вяьаожеожала вочукзиьтчегоаьаоэуд аочукзиьтчего вся обой ухуояуунювчапосу укегоьвхсуоэкуда и тоясукввожявхуожеожявоялвьиьаоэкижаьтчуоаоэуьбда возисяазиьтчегониььориоэуяьвлчвводв жвк увориличавосбкяиому посучвдчуопочадвхуочвоунвюиы\n",
      "\n",
      "iter 30000 : вяъаохеохала вочуэшиътчегоаъаозуд аочуэшиътчего вся обой укуояуунцвчапосу уэегоъвксуозэуда и тоясуэввохявкуохеохявоялвъиъаозэихаътчуоаозуъбда вошисяашиътчегониъъориозуяъвлчвводв хвэ увориличавосбэяиому посучвдчуопочадвкуочвоунвциы\n",
      "\n",
      "iter 45000 : вящаожеожала вочукюищтчегоащаоьуд аочукюищтчего вся обой узуояуунывчапосу укегощвзсуоькуда и тоясукввожявзуожеожявоялвщищаоькижащтчуоаоьущбда воюисяаюищтчегонищщориоьуящвлчвводв жвк увориличавосбкяиому посучвдчуопочадвзуочвоунвыиц\n",
      "\n",
      "iter 60000 : вяюаожеожала вочущшиютчегоаюаозун аочущшиютчего вся обой уцуояууьхвчапосу ущегоювцсуозщуна и тоясущввожявцуожеожявоялвюиюаозщижаютчуоаозуюбна вошисяашиютчегоьиююориозуяювлчввонв жвщ увориличавосбщяиому посучвнчуопочанвцуочвоуьвхиэ\n",
      "\n",
      "iter 75000 : вяхаожеожала вочущфихтчегоахаоьуд аочущфихтчего вся обой уэуояуунзвчапосу ущегохвэсуоьщуда и тоясущввожявэуожеожявоялвхихаоьщижахтчуоаоьухбда вофисяафихтчегониххориоьуяхвлчвводв жвщ увориличавосбщяиому посучвдчуопочадвэуочвоунвзиъ\n",
      "\n",
      "iter 90000 : вяъаожеожала вочукзиътчегоаъаоыуд аочукзиътчего вся обой уюуояууншвчапосу укегоъвюсуоыкуда и тоясукввожявюуожеожявоялвъиъаоыкижаътчуоаоыуъбда возисяазиътчегониъъориоыуяъвлчвводв жвк увориличавосбкяиому посучвдчуопочадвюуочвоунвшиф\n",
      "\n",
      "Iterations 100000, accepted 12101, rejected 87899\n"
     ]
    }
   ],
   "source": [
    "n = 5\n",
    "\n",
    "alphabet_list = sorted(list(set(plain_text)))\n",
    "\n",
    "scoring_params = count_grams_in_longtext(RU_PATH, n=n)\n",
    "PRINT_STEPS = 15000\n",
    "\n",
    "states, best_state = MCMC_decrypt(100000, plain_text, scoring_params, alphabet_list, n=n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## а тут еще хуже. Лучше всего на 3 граммах, интуитивно кажется что на 4-5 граммах будет лучше угадывать целые фразы, встречаемые и в корпусе и в расшифровываемом тексте"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
